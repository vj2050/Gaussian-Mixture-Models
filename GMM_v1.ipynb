{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#from random import normal\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating gaussian distributions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdata(v):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    dis1=np.random.normal(0,v,50)\n",
    "    dis2=np.random.normal(5,v,50)\n",
    "    dis3=np.random.normal(10,v,50)\n",
    "    A=np.concatenate([dis1,dis2])\n",
    "    X=np.concatenate([A,dis3])\n",
    "    X\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=createdata(1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef plot_hist(data):\\n    plt.figure(figsize=(15,7))\\n    for x in data:\\n        plt.hist(x, bins = 80, normed = True, alpha = 0.7)\\n    #plt.xlim(-10, 20)\\n    plt.figure(figsize=(15,7))\\n    \\nplot_hist(X)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def plot_hist(data):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    for x in data:\n",
    "        plt.hist(x, bins = 80, normed = True, alpha = 0.7)\n",
    "    #plt.xlim(-10, 20)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    \n",
    "plot_hist(X)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to initialize random means, variances and prior probabilities: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(X,K):\n",
    "    \n",
    "    m=np.array([2.,3.,7.])             #random means\n",
    "    #m=np.random.choice(X,size=3)      \n",
    "    v=np.ones((3))                     #random variances set to 1 initially\n",
    "    w=np.ones((K))/K                   #random prior weights set to equal\n",
    "    #posterior probability that each input belongs to each of the 3 gaussians\n",
    "    posterior=np.zeros((len(X),K),dtype=float)\n",
    "    return m,v,w,posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True assignment of data samples to respective Gaussians and means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=[0]*50 + [1]*50 + [2]*50\n",
    "Y\n",
    "M=[0,5,10]\n",
    "V=[1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,true,K):\n",
    "    diff=[]\n",
    "    summ=0    \n",
    "    for j in range(K):\n",
    "        #d=abs(pred[j]-true[j])/true[j]\n",
    "        diff.append((abs(pred[j]-true[j])))\n",
    "    summ=sum(diff)\n",
    "    accu=round(((1-summ)*100),2)    \n",
    "    #accu=summ\n",
    "        \n",
    "    return summ,accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to allocate the probability of each of the data points belonging to each one of the clusters(Soft Allocation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM(X,K,epochs):\n",
    "    N=len(X)\n",
    "    #K=3\n",
    "    pi=math.pi\n",
    "    iterations=epochs\n",
    "    M=[0.,5.,10.]\n",
    "    \n",
    "    for iter in range(iterations):\n",
    "        \n",
    "        #Expection Step : Calculating Posterior probabilities for \n",
    "        for i in range(len(X)):\n",
    "            for k in range(K):\n",
    "\n",
    "                part1=1/math.sqrt(2*pi*(var[k]))\n",
    "                part2=(-1/2)*((X[i]-means[k])**2)\n",
    "                part3= part2/(var[k])\n",
    "                part4=np.exp(part3)\n",
    "                posterior[i][k]=part1 * part4\n",
    "\n",
    "                #posterior[i][k]=wprior[k]*(1/math.sqrt(2*var[k]*pi))*(math.exp(-(1/2)*((X[i]-means[k])**2)))\n",
    "\n",
    "            posterior[i]=posterior[i]/np.sum(posterior[i])\n",
    "        \n",
    "        \n",
    "        #Maximization Step : Updating parameters : mean, variance, and prior probabilities :\n",
    "        meanspred=[]\n",
    "        varpred=[]\n",
    "        diffmean=[]\n",
    "        lossmean=[]\n",
    "        for i in range(K):\n",
    "            wprior[i]=np.sum(posterior[:,i])/N\n",
    "            means[i]=np.dot(posterior[:,i],X[:].T)/(np.sum(posterior[:,i]))\n",
    "            var[i]=np.dot(posterior[:,i],((X-means[i])**2).T)/(np.sum(posterior[:,i]))\n",
    "            meanspred.append(means[i])\n",
    "            varpred.append(var[i])\n",
    "        \n",
    "        ##### Retrieving Predicted class labels from posterior probabilities :\n",
    "        li=[]\n",
    "        for i in range(len(X)):\n",
    "            li.append(np.argmax(posterior[i]))\n",
    "            \n",
    "        ######Accuracy Calculation for Mean and Variance at each iteration :\n",
    "        meanloss,accumean=accuracy(meanspred,M,K)\n",
    "        varloss,accuvar=accuracy(varpred,V,K)\n",
    "        ######\n",
    "        \n",
    "        \n",
    "        print(\"\\n\")    \n",
    "        print(\"Epoch \" + str(iter+1) + \" : \" + \"priorprob=\"+ str(wprior))\n",
    "        print(\"Epoch \" + str(iter+1) + \" : \" + \"mean=\"+ str(means))\n",
    "        print(\"Epoch \" + str(iter+1) + \" : \"+ \"var=\" + str(var))\n",
    "        \n",
    "        \n",
    "        #print(meanspred)\n",
    "        print(\"Total mean loss is=> \", meanloss)\n",
    "        print(\"Accuracy of means after Epoch {} : {}%\".format(iter+1, accumean))\n",
    "        print(\"Total variance loss is=> \", varloss)\n",
    "        print(\"Accuracy of variance after Epoch {} : {}%\".format(iter+1, accuvar))\n",
    "        totalaccuracy = round((accuracy_score(li, Y)*100),2)\n",
    "        print(\"Accuracy of allocation after Epoch {} : {}%\".format(iter+1, totalaccuracy))\n",
    "        #totalaccuracy\n",
    "        \n",
    "        \n",
    "    return (wprior, means,var,totalaccuracy,li)\n",
    "    #means.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1 : priorprob=[0.31686045 0.18882409 0.49431546]\n",
      "Epoch 1 : mean=[0.33717436 3.66738246 8.75161024]\n",
      "Epoch 1 : var=[2.35235318 2.39087316 5.5254408 ]\n",
      "Total mean loss is=>  2.91818165515591\n",
      "Accuracy of means after Epoch 1 : -191.82%\n",
      "Total variance loss is=>  7.268667138969127\n",
      "Accuracy of variance after Epoch 1 : -626.87%\n",
      "Accuracy of allocation after Epoch 1 : 82.0%\n",
      "\n",
      "\n",
      "Epoch 2 : priorprob=[0.29596336 0.28383699 0.42019965]\n",
      "Epoch 2 : mean=[0.07440818 4.23741447 9.28279348]\n",
      "Epoch 2 : var=[1.55502693 2.29544849 4.62908539]\n",
      "Total mean loss is=>  1.5542002307001992\n",
      "Accuracy of means after Epoch 2 : -55.42%\n",
      "Total variance loss is=>  5.479560812105378\n",
      "Accuracy of variance after Epoch 2 : -447.96%\n",
      "Accuracy of allocation after Epoch 2 : 94.0%\n",
      "\n",
      "\n",
      "Epoch 3 : priorprob=[0.30453275 0.31415929 0.38130796]\n",
      "Epoch 3 : mean=[0.01434501 4.55744772 9.67525195]\n",
      "Epoch 3 : var=[1.18304609 1.63451487 3.33138189]\n",
      "Total mean loss is=>  0.7816453335035896\n",
      "Accuracy of means after Epoch 3 : 21.84%\n",
      "Total variance loss is=>  3.148942844587064\n",
      "Accuracy of variance after Epoch 3 : -214.89%\n",
      "Accuracy of allocation after Epoch 3 : 97.33%\n",
      "\n",
      "\n",
      "Epoch 4 : priorprob=[0.31585554 0.32813163 0.35601283]\n",
      "Epoch 4 : mean=[0.04607395 4.74156401 9.98552153]\n",
      "Epoch 4 : var=[1.15981032 1.13903816 2.09969777]\n",
      "Total mean loss is=>  0.31898841079222995\n",
      "Accuracy of means after Epoch 4 : 68.1%\n",
      "Total variance loss is=>  1.3985462504678543\n",
      "Accuracy of variance after Epoch 4 : -39.85%\n",
      "Accuracy of allocation after Epoch 4 : 98.0%\n"
     ]
    }
   ],
   "source": [
    "means,var,wprior,posterior=initialize(X,3)\n",
    "#means,var,wprior,posterior.shape\n",
    "wprior,means,var,totalaccuracy,li=GMM(X,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training Accuracy after last epoch :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.15981032, 1.13903816, 2.09969777])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy of allocation : 98.0%\n",
      "Number of samples classifed for Gaussians 0, 1, 2 :  48 51 51\n"
     ]
    }
   ],
   "source": [
    "finalaccuracy = round((accuracy_score(li, Y)*100),2)\n",
    "print(\"Final Accuracy of allocation : {}%\".format(finalaccuracy))\n",
    "print(\"Number of samples classifed for Gaussians 0, 1, 2 : \",li.count(0),li.count(1),li.count(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initially each of the Gaussians consisted of 50 data points. Here we can see that it successfully predicted and classified the total 150 data points in 3 respective Gaussians(0,1,2). \n",
    "* Here I ran my algortithm for 4 epochs since I noticed that after 4th epoch my algorithm started to show no change in parameters which are mean, variance and prior probabilities. Also, when I how many data points were part of each cluster, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different variances :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1 : priorprob=[0.30379591 0.16129193 0.53491216]\n",
      "Epoch 1 : mean=[-0.41752964  3.32022977  9.28651244]\n",
      "Epoch 1 : var=[ 7.26556547  1.90157733 10.5107976 ]\n",
      "Total mean loss is=>  2.8107874259869305\n",
      "Accuracy of means after Epoch 1 : -181.08%\n",
      "Total variance loss is=>  16.677940397926992\n",
      "Accuracy of variance after Epoch 1 : -1567.79%\n",
      "Accuracy of allocation after Epoch 1 : 66.0%\n",
      "\n",
      "\n",
      "Epoch 2 : priorprob=[0.27202643 0.24936382 0.47860975]\n",
      "Epoch 2 : mean=[-0.52296372  3.70009393  9.60227255]\n",
      "Epoch 2 : var=[ 8.99009478  2.86158074 11.11711744]\n",
      "Total mean loss is=>  2.220597241527668\n",
      "Accuracy of means after Epoch 2 : -122.06%\n",
      "Total variance loss is=>  19.968792964705695\n",
      "Accuracy of variance after Epoch 2 : -1896.88%\n",
      "Accuracy of allocation after Epoch 2 : 72.67%\n",
      "\n",
      "\n",
      "Epoch 3 : priorprob=[0.27711229 0.28848778 0.43439994]\n",
      "Epoch 3 : mean=[-0.38087645  4.07237943  9.9145151 ]\n",
      "Epoch 3 : var=[ 9.60834796  3.74225517 11.1201174 ]\n",
      "Total mean loss is=>  1.3939819191528322\n",
      "Accuracy of means after Epoch 3 : -39.4%\n",
      "Total variance loss is=>  21.470720535899314\n",
      "Accuracy of variance after Epoch 3 : -2047.07%\n",
      "Accuracy of allocation after Epoch 3 : 73.33%\n",
      "\n",
      "\n",
      "Epoch 4 : priorprob=[0.28845632 0.31073309 0.40081059]\n",
      "Epoch 4 : mean=[-0.22397572  4.39244573 10.16909213]\n",
      "Epoch 4 : var=[ 9.91928415  4.37978983 11.02254412]\n",
      "Total mean loss is=>  1.0006221193827125\n",
      "Accuracy of means after Epoch 4 : -0.06%\n",
      "Total variance loss is=>  22.321618089327224\n",
      "Accuracy of variance after Epoch 4 : -2132.16%\n",
      "Accuracy of allocation after Epoch 4 : 72.67%\n",
      "\n",
      "\n",
      "Epoch 5 : priorprob=[0.30032895 0.32254957 0.37712148]\n",
      "Epoch 5 : mean=[-0.08931848  4.64172266 10.35684882]\n",
      "Epoch 5 : var=[10.10580457  4.7823485  10.91583297]\n",
      "Total mean loss is=>  0.8044446304341704\n",
      "Accuracy of means after Epoch 5 : 19.56%\n",
      "Total variance loss is=>  22.80398604147387\n",
      "Accuracy of variance after Epoch 5 : -2180.4%\n",
      "Accuracy of allocation after Epoch 5 : 73.33%\n",
      "\n",
      "\n",
      "Epoch 6 : priorprob=[0.31057792 0.3284751  0.36094698]\n",
      "Epoch 6 : mean=[ 0.01512184  4.82546131 10.49021224]\n",
      "Epoch 6 : var=[10.22925447  5.0177765  10.81520674]\n",
      "Total mean loss is=>  0.6798727753167402\n",
      "Accuracy of means after Epoch 6 : 32.01%\n",
      "Total variance loss is=>  23.06223771141684\n",
      "Accuracy of variance after Epoch 6 : -2206.22%\n",
      "Accuracy of allocation after Epoch 6 : 72.67%\n",
      "\n",
      "\n",
      "Epoch 7 : priorprob=[0.31864401 0.33139698 0.349959  ]\n",
      "Epoch 7 : mean=[ 0.09167562  4.95725452 10.58443922]\n",
      "Epoch 7 : var=[10.31192985  5.14804772 10.72507354]\n",
      "Total mean loss is=>  0.7188603258164719\n",
      "Accuracy of means after Epoch 7 : 28.11%\n",
      "Total variance loss is=>  23.185051116140908\n",
      "Accuracy of variance after Epoch 7 : -2218.51%\n",
      "Accuracy of allocation after Epoch 7 : 72.67%\n",
      "\n",
      "\n",
      "Epoch 8 : priorprob=[0.32469278 0.33285539 0.34245183]\n",
      "Epoch 8 : mean=[ 0.14586717  5.05066087 10.65156869]\n",
      "Epoch 8 : var=[10.36454448  5.21453249 10.64634785]\n",
      "Total mean loss is=>  0.8480967290061662\n",
      "Accuracy of means after Epoch 8 : 15.19%\n",
      "Total variance loss is=>  23.225424823737047\n",
      "Accuracy of variance after Epoch 8 : -2222.54%\n",
      "Accuracy of allocation after Epoch 8 : 72.0%\n",
      "\n",
      "\n",
      "Epoch 9 : priorprob=[0.32911691 0.33360453 0.33727855]\n",
      "Epoch 9 : mean=[ 0.18328717  5.11665916 10.70002002]\n",
      "Epoch 9 : var=[10.39452501  5.24251216 10.57821177]\n",
      "Total mean loss is=>  0.9999663460718149\n",
      "Accuracy of means after Epoch 9 : 0.0%\n",
      "Total variance loss is=>  23.215248937796204\n",
      "Accuracy of variance after Epoch 9 : -2221.52%\n",
      "Accuracy of allocation after Epoch 9 : 71.33%\n",
      "\n",
      "\n",
      "Epoch 10 : priorprob=[0.33231536 0.33400415 0.33368049]\n",
      "Epoch 10 : mean=[ 0.20857189  5.16343348 10.73551228]\n",
      "Epoch 10 : var=[10.4078048   5.24722343 10.51931697]\n",
      "Total mean loss is=>  1.10751764188257\n",
      "Accuracy of means after Epoch 10 : -10.75%\n",
      "Total variance loss is=>  23.17434519777762\n",
      "Accuracy of variance after Epoch 10 : -2217.43%\n",
      "Accuracy of allocation after Epoch 10 : 70.67%\n",
      "Final Accuracy of allocation : 70.67%\n",
      "Number of samples classifed for Gaussians 0, 1, 2 :  47 56 47\n"
     ]
    }
   ],
   "source": [
    "X2=createdata(3)\n",
    "means,var,wprior,posterior=initialize(X2,3)\n",
    "wprior,means,var,totalaccuracy2,li2=GMM(X2,3,10)\n",
    "finalaccuracy2 = round((accuracy_score(li2, Y)*100),2)\n",
    "print(\"Final Accuracy of allocation : {}%\".format(finalaccuracy2))\n",
    "print(\"Number of samples classifed for Gaussians 0, 1, 2 : \",li2.count(0),li2.count(1),li2.count(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1 : priorprob=[0.32099957 0.14138499 0.53761544]\n",
      "Epoch 1 : mean=[-1.54752871  3.31178119 10.51948588]\n",
      "Epoch 1 : var=[13.98669165  1.8805     18.07563298]\n",
      "Total mean loss is=>  3.7552334015839577\n",
      "Accuracy of means after Epoch 1 : -275.52%\n",
      "Total variance loss is=>  30.94282463249006\n",
      "Accuracy of variance after Epoch 1 : -2994.28%\n",
      "Accuracy of allocation after Epoch 1 : 55.33%\n",
      "\n",
      "\n",
      "Epoch 2 : priorprob=[0.28882951 0.22971814 0.48145235]\n",
      "Epoch 2 : mean=[-1.54117813  3.5851093  10.90137209]\n",
      "Epoch 2 : var=[18.62759833  3.00261374 19.44275524]\n",
      "Total mean loss is=>  3.8574409197300854\n",
      "Accuracy of means after Epoch 2 : -285.74%\n",
      "Total variance loss is=>  38.07296731621261\n",
      "Accuracy of variance after Epoch 2 : -3707.3%\n",
      "Accuracy of allocation after Epoch 2 : 57.33%\n",
      "\n",
      "\n",
      "Epoch 3 : priorprob=[0.29346914 0.26741311 0.43911776]\n",
      "Epoch 3 : mean=[-1.24711314  3.90304076 11.27074235]\n",
      "Epoch 3 : var=[21.06948723  4.31769766 19.66699698]\n",
      "Total mean loss is=>  3.614814729350188\n",
      "Accuracy of means after Epoch 3 : -261.48%\n",
      "Total variance loss is=>  42.05418187732707\n",
      "Accuracy of variance after Epoch 3 : -4105.42%\n",
      "Accuracy of allocation after Epoch 3 : 58.0%\n",
      "\n",
      "\n",
      "Epoch 4 : priorprob=[0.30189226 0.29336717 0.40474057]\n",
      "Epoch 4 : mean=[-0.98427124  4.18930851 11.6001626 ]\n",
      "Epoch 4 : var=[22.55781724  5.51393345 19.6492959 ]\n",
      "Total mean loss is=>  3.3951253273498434\n",
      "Accuracy of means after Epoch 4 : -239.51%\n",
      "Total variance loss is=>  44.72104658411186\n",
      "Accuracy of variance after Epoch 4 : -4372.1%\n",
      "Accuracy of allocation after Epoch 4 : 58.67%\n",
      "\n",
      "\n",
      "Epoch 5 : priorprob=[0.31056034 0.30897623 0.38046343]\n",
      "Epoch 5 : mean=[-0.77434744  4.40934265 11.84086901]\n",
      "Epoch 5 : var=[23.46444577  6.49525926 19.59273688]\n",
      "Total mean loss is=>  3.2058737960444788\n",
      "Accuracy of means after Epoch 5 : -220.59%\n",
      "Total variance loss is=>  46.55244190588827\n",
      "Accuracy of variance after Epoch 5 : -4555.24%\n",
      "Accuracy of allocation after Epoch 5 : 60.67%\n",
      "\n",
      "\n",
      "Epoch 6 : priorprob=[0.31776725 0.31816913 0.36406362]\n",
      "Epoch 6 : mean=[-0.61627444  4.56793028 12.00168131]\n",
      "Epoch 6 : var=[24.04442665  7.28398954 19.5777663 ]\n",
      "Total mean loss is=>  3.050025470568762\n",
      "Accuracy of means after Epoch 6 : -205.0%\n",
      "Total variance loss is=>  47.906182491329375\n",
      "Accuracy of variance after Epoch 6 : -4690.62%\n",
      "Accuracy of allocation after Epoch 6 : 59.33%\n",
      "\n",
      "\n",
      "Epoch 7 : priorprob=[0.32310301 0.3238009  0.35309609]\n",
      "Epoch 7 : mean=[-0.50026642  4.67856881 12.10330836]\n",
      "Epoch 7 : var=[24.44525434  7.92112515 19.62145536]\n",
      "Total mean loss is=>  2.925005970894587\n",
      "Accuracy of means after Epoch 7 : -192.5%\n",
      "Total variance loss is=>  48.98783485403996\n",
      "Accuracy of variance after Epoch 7 : -4798.78%\n",
      "Accuracy of allocation after Epoch 7 : 58.67%\n",
      "\n",
      "\n",
      "Epoch 8 : priorprob=[0.32681162 0.32739587 0.34579251]\n",
      "Epoch 8 : mean=[-0.41489415  4.75395745 12.16360728]\n",
      "Epoch 8 : var=[24.74682695  8.44121743 19.71502702]\n",
      "Total mean loss is=>  2.8245439745167222\n",
      "Accuracy of means after Epoch 8 : -182.45%\n",
      "Total variance loss is=>  49.9030713966391\n",
      "Accuracy of variance after Epoch 8 : -4890.31%\n",
      "Accuracy of allocation after Epoch 8 : 58.67%\n",
      "\n",
      "\n",
      "Epoch 9 : priorprob=[0.3292939  0.32975178 0.34095432]\n",
      "Epoch 9 : mean=[-0.35069326  4.80410456 12.19587796]\n",
      "Epoch 9 : var=[24.99285638  8.8705707  19.84331082]\n",
      "Total mean loss is=>  2.7424666654582315\n",
      "Accuracy of means after Epoch 9 : -174.25%\n",
      "Total variance loss is=>  50.70673790179653\n",
      "Accuracy of variance after Epoch 9 : -4970.67%\n",
      "Accuracy of allocation after Epoch 9 : 58.67%\n",
      "\n",
      "\n",
      "Epoch 10 : priorprob=[0.3309115  0.33131608 0.33777242]\n",
      "Epoch 10 : mean=[-0.30080274  4.8364267  12.20961527]\n",
      "Epoch 10 : var=[25.20748584  9.22917207 19.99206711]\n",
      "Total mean loss is=>  2.673991307231115\n",
      "Accuracy of means after Epoch 10 : -167.4%\n",
      "Total variance loss is=>  51.428725025873874\n",
      "Accuracy of variance after Epoch 10 : -5042.87%\n",
      "Accuracy of allocation after Epoch 10 : 58.67%\n",
      "Final Accuracy of allocation : 58.67%\n",
      "Number of samples classifed for Gaussians 0, 1, 2 :  38 63 49\n"
     ]
    }
   ],
   "source": [
    "X3=createdata(5)\n",
    "means,var,wprior,posterior=initialize(X3,3)\n",
    "wprior,means,var,totalaccuracy3,li3=GMM(X3,3,10)\n",
    "finalaccuracy3 = round((accuracy_score(li3, Y)*100),2)\n",
    "print(\"Final Accuracy of allocation : {}%\".format(finalaccuracy3))\n",
    "print(\"Number of samples classifed for Gaussians 0, 1, 2 : \",li3.count(0),li3.count(1),li3.count(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration 4 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1 : priorprob=[0.38434615 0.08659788 0.52905597]\n",
      "Epoch 1 : mean=[-4.6580071   3.11694109 14.69448081]\n",
      "Epoch 1 : var=[37.54829617  2.02034978 48.59829648]\n",
      "Total mean loss is=>  11.235546817487464\n",
      "Accuracy of means after Epoch 1 : -1023.55%\n",
      "Total variance loss is=>  85.16694242040813\n",
      "Accuracy of variance after Epoch 1 : -8416.69%\n",
      "Accuracy of allocation after Epoch 1 : 43.33%\n",
      "\n",
      "\n",
      "Epoch 2 : priorprob=[0.3477011  0.17256861 0.47973029]\n",
      "Epoch 2 : mean=[-4.67859324  3.1957804  15.27753612]\n",
      "Epoch 2 : var=[48.64916174  3.46394392 51.86050917]\n",
      "Total mean loss is=>  11.760348961157352\n",
      "Accuracy of means after Epoch 2 : -1076.03%\n",
      "Total variance loss is=>  100.97361482676692\n",
      "Accuracy of variance after Epoch 2 : -9997.36%\n",
      "Accuracy of allocation after Epoch 2 : 44.0%\n",
      "\n",
      "\n",
      "Epoch 3 : priorprob=[0.34473224 0.2027475  0.45252027]\n",
      "Epoch 3 : mean=[-4.41569306  3.30310175 15.703987  ]\n",
      "Epoch 3 : var=[54.56295141  5.66824926 51.36808334]\n",
      "Total mean loss is=>  11.81657832163814\n",
      "Accuracy of means after Epoch 3 : -1081.66%\n",
      "Total variance loss is=>  108.59928401232105\n",
      "Accuracy of variance after Epoch 3 : -10759.93%\n",
      "Accuracy of allocation after Epoch 3 : 46.0%\n",
      "\n",
      "\n",
      "Epoch 4 : priorprob=[0.33710872 0.23663704 0.42625424]\n",
      "Epoch 4 : mean=[-4.297512    3.41666938 16.17357413]\n",
      "Epoch 4 : var=[58.94737614  8.88535254 49.90441664]\n",
      "Total mean loss is=>  12.054416754424006\n",
      "Accuracy of means after Epoch 4 : -1105.44%\n",
      "Total variance loss is=>  114.73714531621353\n",
      "Accuracy of variance after Epoch 4 : -11373.71%\n",
      "Accuracy of allocation after Epoch 4 : 46.67%\n",
      "\n",
      "\n",
      "Epoch 5 : priorprob=[0.32721513 0.26927694 0.40350793]\n",
      "Epoch 5 : mean=[-4.23556038  3.4781826  16.61226677]\n",
      "Epoch 5 : var=[62.48603288 12.46709236 48.20153823]\n",
      "Total mean loss is=>  12.369644548479137\n",
      "Accuracy of means after Epoch 5 : -1136.96%\n",
      "Total variance loss is=>  120.15466347598661\n",
      "Accuracy of variance after Epoch 5 : -11915.47%\n",
      "Accuracy of allocation after Epoch 5 : 46.67%\n",
      "\n",
      "\n",
      "Epoch 6 : priorprob=[0.3208326  0.29202534 0.38714205]\n",
      "Epoch 6 : mean=[-4.11307502  3.48808883 16.93134194]\n",
      "Epoch 6 : var=[65.5866755  15.70892363 46.86534875]\n",
      "Total mean loss is=>  12.556328125833566\n",
      "Accuracy of means after Epoch 6 : -1155.63%\n",
      "Total variance loss is=>  125.1609478800751\n",
      "Accuracy of variance after Epoch 6 : -12416.09%\n",
      "Accuracy of allocation after Epoch 6 : 48.0%\n",
      "\n",
      "\n",
      "Epoch 7 : priorprob=[0.31855561 0.30591    0.37553438]\n",
      "Epoch 7 : mean=[-3.92298925  3.48650468 17.14082688]\n",
      "Epoch 7 : var=[68.46999583 18.45020614 46.13272672]\n",
      "Total mean loss is=>  12.577311457956725\n",
      "Accuracy of means after Epoch 7 : -1157.73%\n",
      "Total variance loss is=>  130.0529286923322\n",
      "Accuracy of variance after Epoch 7 : -12905.29%\n",
      "Accuracy of allocation after Epoch 7 : 49.33%\n",
      "\n",
      "\n",
      "Epoch 8 : priorprob=[0.31888495 0.31424555 0.3668695 ]\n",
      "Epoch 8 : mean=[-3.70033192  3.48549034 17.27730577]\n",
      "Epoch 8 : var=[71.15427535 20.73711325 45.88294674]\n",
      "Total mean loss is=>  12.492147351178534\n",
      "Accuracy of means after Epoch 8 : -1149.21%\n",
      "Total variance loss is=>  134.77433533891394\n",
      "Accuracy of variance after Epoch 8 : -13377.43%\n",
      "Accuracy of allocation after Epoch 8 : 50.0%\n",
      "\n",
      "\n",
      "Epoch 9 : priorprob=[0.32041824 0.31940183 0.36017994]\n",
      "Epoch 9 : mean=[-3.47510948  3.48254135 17.36630494]\n",
      "Epoch 9 : var=[73.61157645 22.65523403 45.93288287]\n",
      "Total mean loss is=>  12.358873069849656\n",
      "Accuracy of means after Epoch 9 : -1135.89%\n",
      "Total variance loss is=>  139.19969335605248\n",
      "Accuracy of variance after Epoch 9 : -13819.97%\n",
      "Accuracy of allocation after Epoch 9 : 50.0%\n",
      "\n",
      "\n",
      "Epoch 10 : priorprob=[0.32227704 0.32277042 0.35495254]\n",
      "Epoch 10 : mean=[-3.2637792   3.47402308 17.42307723]\n",
      "Epoch 10 : var=[75.83115365 24.27901342 46.15204845]\n",
      "Total mean loss is=>  12.21283334752516\n",
      "Accuracy of means after Epoch 10 : -1121.28%\n",
      "Total variance loss is=>  143.26221551581315\n",
      "Accuracy of variance after Epoch 10 : -14226.22%\n",
      "Accuracy of allocation after Epoch 10 : 50.67%\n",
      "Final Accuracy of allocation : 50.67%\n",
      "Number of samples classifed for Gaussians 0, 1, 2 :  36 63 51\n"
     ]
    }
   ],
   "source": [
    "X4=createdata(10)\n",
    "means,var,wprior,posterior=initialize(X4,3)\n",
    "wprior,means,var,totalaccuracy4,li4 = GMM(X4,3,10)\n",
    "finalaccuracy4 = round((accuracy_score(li4, Y)*100),2)\n",
    "print(\"Final Accuracy of allocation : {}%\".format(finalaccuracy4))\n",
    "print(\"Number of samples classifed for Gaussians 0, 1, 2 : \",li4.count(0),li4.count(1),li4.count(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see a decrease in accuracies when we ran our algorithm for less number of epochs. In our algorithm, we stopped when our posterior probabilities showed almost no change. After trying different values for variance, we noticed that as variance increases, our GMM algorithm takes many iterations to converge. GMM is much more flexible allowing us to generate much better fitting distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
